<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>AI Pet That Learns My Voice</title>
  <style>
    :root { --border:#ddd; --muted:#555; }
    body { font-family: Arial, sans-serif; max-width: 1100px; margin: 18px auto; padding: 0 12px; }
    h1 { margin: 0 0 10px 0; font-size: 44px; }
    .muted { color: var(--muted); }
    .row { display:flex; gap:16px; flex-wrap:wrap; align-items:flex-start; }
    .card { border:1px solid var(--border); border-radius:14px; padding:14px; flex:1; min-width:320px; }
    .btn { padding:10px 14px; border-radius:10px; border:1px solid #999; background:#f6f6f6; cursor:pointer; }
    .btn:disabled { opacity:.5; cursor:not-allowed; }
    .pill { display:inline-block; padding:6px 10px; border-radius:999px; border:1px solid var(--border); margin:4px 6px 0 0; font-size:14px; }
    #status { white-space:pre-wrap; }

    .petStage { height: 300px; display:flex; align-items:flex-end; justify-content:center; border:1px solid var(--border); border-radius:12px; padding:10px; background:#fff; }
    #petImg { width: 320px; height:auto; }

    .jumpAnim { animation: jumpBounce 650ms ease-in-out 1; }
    @keyframes jumpBounce {
      0%   { transform: translateY(0); }
      40%  { transform: translateY(-90px); }
      70%  { transform: translateY(0); }
      100% { transform: translateY(0); }
    }

    .sleepDim { opacity: 0.82; filter: brightness(0.95); }
  </style>
</head>
<body>
  <h1>AI Pet That Learns My Voice</h1>
  <p class="muted">Commands: <b>Sit</b>, <b>Jump</b>, <b>Sleep</b>. Use the headset microphone. Buttons are the backup.</p>

  <div class="row">
    <div class="card">
      <h2>Controls</h2>
      <p>
        <button id="btnStart" class="btn">Start Listening</button>
        <button id="btnStop" class="btn" disabled>Stop</button>
      </p>

      <p class="muted">If it’s noisy, use buttons:</p>
      <p>
        <button class="btn btnAction" data-action="Sit">Sit</button>
        <button class="btn btnAction" data-action="Jump">Jump</button>
        <button class="btn btnAction" data-action="Sleep">Sleep</button>
        <button class="btn btnAction" data-action="Stand">Stand</button>
      </p>

      <h3>Live Prediction</h3>
      <div id="top" style="font-size:18px;"></div>
      <div id="scores"></div>

      <h3>Status</h3>
      <div id="status" class="muted">Loading…</div>

      <hr />
      <div class="muted">
        <b>Setup:</b> Put your Teachable Machine exported files in <code>./model/</code>:
        <code>model.json</code>, <code>metadata.json</code>, <code>weights.bin</code>.
      </div>
    </div>

    <div class="card">
      <h2>Pet</h2>
      <div class="petStage">
        <img id="petImg" src="pet-stand.png" alt="AI Pet" />
      </div>
      <div id="petText" style="font-size:18px; margin-top:8px;">Waiting…</div>
      <p class="muted">Tip: keep the mic close to the child’s mouth.</p>
    </div>
  </div>

  <!--
    Dependency loading notes:
    - Your screenshots show "tmAudio is not defined" AND the Network tab shows
      teachablemachine-audio.min.js failing to load.
    - That happens when the Teachable Machine Audio library script is blocked
      (common on school networks) or the CDN has a transient failure.
    - Fix: load dependencies with a fallback list (jsDelivr + unpkg).
  -->
  <script>
    // Load a script with fallback URLs. Returns when the script is available.
    function loadScriptWithFallback(urls, globalName) {
      return new Promise((resolve, reject) => {
        let i = 0;
        const tryNext = () => {
          if (i >= urls.length) {
            reject(new Error(`Failed loading ${globalName || 'script'} from all CDNs.`));
            return;
          }
          const url = urls[i++];
          const s = document.createElement('script');
          s.src = url;
          s.async = true;
          s.crossOrigin = 'anonymous';
          s.onload = () => resolve(url);
          s.onerror = () => {
            s.remove();
            tryNext();
          };
          document.head.appendChild(s);
        };
        // If the global is already present, skip loading.
        if (globalName && window[globalName]) {
          resolve('already-loaded');
          return;
        }
        tryNext();
      });
    }

    // Ensure TFJS + TeachableMachine Audio are available.
    async function ensureDeps() {
      // Your screenshots show the TeachableMachine Audio helper script being blocked
      // ("tmAudio is not defined" + Network failures). To avoid that dependency,
      // we use the TensorFlow SpeechCommands API directly.
      await loadScriptWithFallback(
        [
          'https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js',
          'https://unpkg.com/@tensorflow/tfjs@4.20.0/dist/tf.min.js'
        ],
        'tf'
      );

      await loadScriptWithFallback(
        [
          // Match Teachable Machine TMv2 exports (metadata shows tfjsSpeechCommandsVersion 0.4.0)
          'https://cdn.jsdelivr.net/npm/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js',
          'https://unpkg.com/@tensorflow-models/speech-commands@0.4.0/dist/speech-commands.min.js'
        ],
        'speechCommands'
      );
    }
  </script>

  <script>
    const MODEL_DIR = "./model/";

    // Stability controls
    const THRESHOLD = 0.82;   // raise if false triggers
    const STREAK_N  = 2;      // require N consecutive hits

    let model, recognizer;
    let isListening = false;
    let lastLabel = null;
    let streak = 0;

    const elTop = document.getElementById("top");
    const elScores = document.getElementById("scores");
    const elStatus = document.getElementById("status");
    const elPetText = document.getElementById("petText");
    const elPetImg = document.getElementById("petImg");
    const btnStart = document.getElementById("btnStart");
    const btnStop = document.getElementById("btnStop");

    function showStatus(msg) {
      elStatus.textContent = msg;
    }

    function normalizeAction(label) {
      const s = String(label || "").toLowerCase();
      if (s.includes("sit")) return "Sit";
      if (s.includes("jump")) return "Jump";
      if (s.includes("sleep")) return "Sleep";
      if (s.includes("stand")) return "Stand";
      // If your Teachable Machine labels are exactly Sit/Jump/Sleep, this won't be used.
      return null;
    }

    function setPet(action, source = "Voice") {
      elPetImg.className = "";
      if (action === "Sit") {
        elPetImg.src = "pet-sit.png";
        elPetText.textContent = `Sitting (from ${source})`;
      } else if (action === "Jump") {
        elPetImg.src = "pet-jump.png";
        // re-trigger animation reliably
        void elPetImg.offsetWidth;
        elPetImg.classList.add("jumpAnim");
        elPetText.textContent = `Jumping (from ${source})`;
      } else if (action === "Sleep") {
        elPetImg.src = "pet-sleep.png";
        elPetImg.classList.add("sleepDim");
        elPetText.textContent = `Sleeping (from ${source})`;
      } else {
        elPetImg.src = "pet-stand.png";
        elPetText.textContent = `Standing (from ${source})`;
      }
    }

    function renderScores(predictions) {
      const sorted = [...predictions].sort((a,b) => b.probability - a.probability);
      const top = sorted[0];
      elTop.textContent = `Top: ${top.className} (${Math.round(top.probability*100)}%)`;
      elScores.innerHTML = sorted.map(p => {
        const pct = Math.round(p.probability * 100);
        return `<span class="pill">${p.className}: ${pct}%</span>`;
      }).join("");
    }

    function considerTrigger(label, prob) {
      const action = normalizeAction(label);
      if (!action || prob < THRESHOLD) {
        lastLabel = null;
        streak = 0;
        return;
      }
      if (action === lastLabel) streak++; else { lastLabel = action; streak = 1; }
      if (streak >= STREAK_N) {
        setPet(action, "Voice");
        streak = 0;
        lastLabel = null;
      }
    }

    async function verifyModelFiles() {
      // If you opened index.html directly (file://), fetching files may be blocked.
      if (location.protocol === 'file:') {
        throw new Error(
          "You opened this via file://\n\n" +
          "Browsers often block loading model files from file://\n" +
          "Run a local web server or host it (GitHub Pages / Netlify)."
        );
      }

      const required = ["model.json", "metadata.json", "weights.bin"]; 
      for (const f of required) {
        const r = await fetch(MODEL_DIR + f, { cache: 'no-store' });
        if (!r.ok) throw new Error(`Missing or not served: ${MODEL_DIR}${f} (HTTP ${r.status})`);
      }
    }

    async function loadModel() {
      // Ensure JS deps first (this is the part that was failing for you).
      showStatus("Loading libraries…");
      await ensureDeps();

      showStatus("Checking model files…");
      await verifyModelFiles();

      showStatus("Loading model…");
      // Teachable Machine v2 audio exports are Speech Commands compatible.
      recognizer = speechCommands.create(
        'BROWSER_FFT',
        undefined,
        MODEL_DIR + 'model.json',
        MODEL_DIR + 'metadata.json'
      );
      await recognizer.ensureModelLoaded();
      labels = recognizer.wordLabels();
      showStatus("Model loaded. Click Start Listening.");
    }

    async function startListening() {
      try {
        if (!recognizer) await loadModel();
        if (isListening) return;

        // Start microphone classification.
        recognizer.listen(({ scores }) => {
          // Convert to the same shape used by renderScores.
          const predictions = labels.map((name, i) => ({ className: name, probability: scores[i] }));
          renderScores(predictions);

          // Pick top class (excluding background noise).
          let top = null;
          for (const p of predictions) {
            if (normalizeAction(p.className) === null) continue;
            if (!top || p.probability > top.probability) top = p;
          }
          if (top) considerTrigger(top.className, top.probability);
        }, {
          // 0.75 keeps it responsive but avoids constant false triggers.
          probabilityThreshold: 0.0,
          overlapFactor: 0.5
        });

        isListening = true;
        btnStart.disabled = true;
        btnStop.disabled = false;
        showStatus("Listening… Speak: Sit / Jump / Sleep");
      } catch (e) {
        showStatus(
          "Model not found / cannot load.\n\n" +
          (e?.message || String(e)) +
          "\n\nFix:\n" +
          "1) Ensure model files are in ./model/\n" +
          "2) Host using a web server (not file://)\n" +
          "3) Refresh and try again."
        );
        console.error(e);
      }
    }

    async function stopListening() {
      if (!recognizer || !isListening) return;
      recognizer.stopListening();
      isListening = false;
      btnStart.disabled = false;
      btnStop.disabled = true;
      showStatus("Stopped. Click Start Listening.");
    }

    btnStart.addEventListener("click", startListening);
    btnStop.addEventListener("click", stopListening);

    document.querySelectorAll(".btnAction").forEach(btn => {
      btn.addEventListener("click", () => setPet(btn.dataset.action, "Buttons"));
    });

    // Initial state
    setPet("Stand", "Buttons");
    loadModel().catch(() => {
      // Defer showing error until user clicks Start (less scary).
      showStatus("Model not loaded yet. Click Start Listening.");
    });
  </script>
</body>
</html>
